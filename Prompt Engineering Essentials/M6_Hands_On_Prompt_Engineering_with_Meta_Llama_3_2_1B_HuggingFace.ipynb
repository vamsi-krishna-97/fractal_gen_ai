{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb6rdwlCsCGt"
   },
   "source": [
    "# Using Llama 3.2 1B SLM with Python & HuggingFace for diverse real-world tasks using Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTzBUFWQ-OWj"
   },
   "source": [
    "In this notebook you will use Meta Llama 3.2 1B SLM via HuggingFace to solve:\n",
    "\n",
    "- Task 1: Zero-shot Classification\n",
    "- Task 2: Few-shot Classification\n",
    "- Task 3: Coding Tasks - Python\n",
    "- Task 4: Coding Tasks - SQL\n",
    "- Task 5: Information Extraction\n",
    "- Task 6: Closed-Domain Question Answering\n",
    "- Task 7: Open-Domain Question Answering\n",
    "- Task 8: Document Summarization\n",
    "- Task 9: Transformation\n",
    "- Task 10: Translation\n",
    "\n",
    "\n",
    "\n",
    "___Created By: Dipanjan (DJ)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install HuggingFace dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23712,
     "status": "ok",
     "timestamp": 1734091284528,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "2evPp14fy258",
    "outputId": "6094bc79-0c94-4d1a-e336-5719fe01332d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.46.2\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (0.34.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.46.2)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.2)\n",
      "  Downloading tokenizers-0.20.3-cp313-cp313-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from transformers==4.46.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (1.1.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->transformers==4.46.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->transformers==4.46.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->transformers==4.46.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->transformers==4.46.2) (2025.4.26)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp313-cp313-macosx_10_12_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl (454 kB)\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed safetensors-0.6.2 tokenizers-0.20.3 transformers-4.46.2\n",
      "Collecting huggingface_hub==0.26.2\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface_hub==0.26.2) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface_hub==0.26.2) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface_hub==0.26.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface_hub==0.26.2) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface_hub==0.26.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface_hub==0.26.2) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from huggingface_hub==0.26.2) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub==0.26.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub==0.26.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub==0.26.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/harsh/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub==0.26.2) (2025.4.26)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.34.5\n",
      "    Uninstalling huggingface-hub-0.34.5:\n",
      "      Successfully uninstalled huggingface-hub-0.34.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 5.45.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.26.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.46.2\n",
    "!pip install huggingface_hub==0.26.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivag8YTWBAHv"
   },
   "source": [
    "## Load Hugging Face Access Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3587,
     "status": "ok",
     "timestamp": 1734091300033,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "nBpPYcHeBAHw",
    "outputId": "055947de-a736-45f8-bdd9-5fd40de8c759"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "hf_key = getpass(\"Enter HuggingFace API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2BFJxHFBAHw"
   },
   "source": [
    "## Configure Key in Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1734091302544,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "R0I1imf4BAHx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = hf_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39G8iunseMTj"
   },
   "source": [
    "## Make sure you have access to Llama 3.2 1B on HuggingFace\n",
    "\n",
    "Certain LLMs are gated like [Meta Llama 3.2 1B Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct) so make sure to apply for access as shown below else you will get an error when using the model.\n",
    "\n",
    "__Note: Sometimes it might take a day to get approval from Meta and if you old token still doesn't work, generate a new access token as you did before and use it.__\n",
    "\n",
    "![](https://i.imgur.com/M88MOu5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDxl5-AHYwi2"
   },
   "source": [
    "## Using LLMs via Hugging Face Inference Client\n",
    "\n",
    "Thankfully HuggingFace has made its new [__Inference Client__](https://huggingface.co/docs/huggingface_hub/en/package_reference/inference_client) free to use with some basic rate limits etc. in place so you don't end up making unlimited requests on its servers.\n",
    "\n",
    "The best part is you can access 150,000+ deep learning models without worrying about your infrastructure. Similar to the inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1734091307467,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "kA9gVCwK0WKd"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Find more models here\n",
    "# https://huggingface.co/models?pipeline_tag=text-generation&sort=trending\n",
    "def get_completion(prompt, api_key=hf_key, model=\"meta-llama/Llama-3.2-1B-Instruct\"):\n",
    "    client = InferenceClient(model=model, api_key=api_key)\n",
    "    chat = [\n",
    "        { \"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    response = client.chat_completion(chat, temperature=0, max_tokens=2048)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TFZjzuGjCOw"
   },
   "source": [
    "## Let's try out the Llama 3.2 1B model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "q98O22DVg7bi",
    "outputId": "af0ae282-9790-4584-c0e8-a7a89f16b3ba"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Generative AI refers to a class of artificial intelligence systems designed to create new content by learning from a dataset, simulating creativity, and generating outputs that are often indistinguishable from human-made content.\n",
       "\n",
       "- It leverages deep learning techniques, such as neural networks, to autonomously produce complex data samples (e.g., images, music, text) by understanding and replicating patterns, structures, and styles found in the training data, enabling applications like content creation, design, and augmentation of existing datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "response = get_completion(prompt='Explain Generative AI in 2 bullet points')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeDkpvGDhMGV"
   },
   "source": [
    "## Task 1: Zero-shot Classification\n",
    "\n",
    "This prompt tests an LLM's text classification capabilities by prompting it to classify a piece of text without providing any examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRbBZB57hT0G"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    f\"\"\"\n",
    "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
    "    The sound quality is impressively clear with just the right amount of bass.\n",
    "    It's also waterproof, which tested true during a recent splashing incident.\n",
    "    Though it's compact, the volume can really fill the space.\n",
    "    The price was a bargain for such high-quality sound.\n",
    "    Shipping was also on point, arriving two days early in secure packaging.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Needed a new kitchen blender, but this model has been a nightmare.\n",
    "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
    "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
    "    I thought the brand meant quality, but this product has proven me wrong.\n",
    "    Plus, it arrived three days late. Definitely not worth the expense.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZwPaViatl7f"
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for review in reviews:\n",
    "  prompt = f\"\"\"\n",
    "              Act as a product review analyst.\n",
    "              Given the following review,\n",
    "              Display the overall sentiment for the review as only one of the following:\n",
    "              Positive, Negative OR Neutral\n",
    "\n",
    "              ```{review}```\n",
    "              \"\"\"\n",
    "  response = get_completion(prompt)\n",
    "  responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdUFkKAmtmBj",
    "outputId": "59ed563e-b656-4b3e-b1f8-a26915e046f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
      "    The sound quality is impressively clear with just the right amount of bass.\n",
      "    It's also waterproof, which tested true during a recent splashing incident.\n",
      "    Though it's compact, the volume can really fill the space.\n",
      "    The price was a bargain for such high-quality sound.\n",
      "    Shipping was also on point, arriving two days early in secure packaging.\n",
      "    \n",
      "Sentiment: The overall sentiment of the review is Positive.\n",
      "\n",
      "The reviewer uses phrases such as \"fantastic\", \"impressively clear\", \"just the right amount of bass\", and \"bargain\" to express their satisfaction with the product. They also mention specific features, such as the waterproof design and secure packaging, which further supports the positive sentiment.\n",
      "------\n",
      "\n",
      "\n",
      "Review: \n",
      "    Needed a new kitchen blender, but this model has been a nightmare.\n",
      "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
      "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
      "    I thought the brand meant quality, but this product has proven me wrong.\n",
      "    Plus, it arrived three days late. Definitely not worth the expense.\n",
      "    \n",
      "Sentiment: The overall sentiment of this review is Negative.\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review, response in zip(reviews, responses):\n",
    "  print('Review:', review)\n",
    "  print('Sentiment:', response)\n",
    "  print('------')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WC6aycZ9Qe3"
   },
   "source": [
    "## Task 2: Few-shot Classification\n",
    "\n",
    "This prompt tests an LLM's text classification capabilities by prompting it to classify a piece of text by providing a few examples of inputs and outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQZdygfUoXGT"
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for review in reviews:\n",
    "  prompt = f\"\"\"\n",
    "              Act as a product review analyst.\n",
    "              Given the following review,\n",
    "              Display only the overall sentiment for the review:\n",
    "\n",
    "              Try to classify it by using the following examples as a reference:\n",
    "\n",
    "              Review: Just received the Laptop I ordered for work, and it's amazing.\n",
    "              Sentiment: üòä\n",
    "\n",
    "              Review: Needed a new mechanical keyboard, but this model has been totally disappointing.\n",
    "              Sentiment: üò°\n",
    "\n",
    "              Review: ```{review}```\n",
    "              \"\"\"\n",
    "  response = get_completion(prompt)\n",
    "  responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCsMzs3QodqR",
    "outputId": "4c2cd5f5-dd7b-4061-b7a5-fdc08933a8f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
      "    The sound quality is impressively clear with just the right amount of bass.\n",
      "    It's also waterproof, which tested true during a recent splashing incident.\n",
      "    Though it's compact, the volume can really fill the space.\n",
      "    The price was a bargain for such high-quality sound.\n",
      "    Shipping was also on point, arriving two days early in secure packaging.\n",
      "    \n",
      "Sentiment: The overall sentiment of the review is: Positive\n",
      "------\n",
      "\n",
      "\n",
      "Review: \n",
      "    Needed a new kitchen blender, but this model has been a nightmare.\n",
      "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
      "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
      "    I thought the brand meant quality, but this product has proven me wrong.\n",
      "    Plus, it arrived three days late. Definitely not worth the expense.\n",
      "    \n",
      "Sentiment: The overall sentiment of the review is: üòä\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review, response in zip(reviews, responses):\n",
    "  print('Review:', review)\n",
    "  print('Sentiment:', response)\n",
    "  print('------')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEKTyfWf9cxY"
   },
   "source": [
    "## Task 3: Coding Tasks - Python\n",
    "\n",
    "This prompt tests an LLM's capabilities for generating python code based on various tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xawr-Co9b0t"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in generating python code\n",
    "\n",
    "Your task is to generate python code\n",
    "to build a Chain of Though prompt pattern using\n",
    "the openai python library\n",
    "\"\"\"\n",
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "2Cenat0G9-Bw",
    "outputId": "029080fe-841c-441a-fc19-23615329990e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's an example of how you can build a Chain of Thought prompt pattern using the OpenAI Python library. This code will generate a prompt that asks a series of questions to the user, encouraging them to think deeply and critically.\n",
       "\n",
       "```python\n",
       "import random\n",
       "\n",
       "class ChainOfThought:\n",
       "    def __init__(self):\n",
       "        self.questions = {\n",
       "            \"What is the meaning of life?\": \"What do you think is the most important aspect of human existence?\",\n",
       "            \"Can you describe a time when you felt truly happy?\": \"What were the circumstances that led to this feeling of happiness?\",\n",
       "            \"What is the biggest risk you've ever taken?\": \"What did you learn from this experience, and how has it shaped your perspective?\",\n",
       "            \"Can you explain the concept of free will?\": \"How do you think our choices and actions are influenced by factors beyond our control?\",\n",
       "            \"What is the most significant challenge you've faced in your life?\": \"How did you overcome this challenge, and what did you learn from the experience?\"\n",
       "        }\n",
       "\n",
       "    def generate_prompt(self):\n",
       "        prompt = random.choice(list(self.questions.keys()))\n",
       "        return prompt\n",
       "\n",
       "    def ask_question(self, prompt):\n",
       "        print(prompt)\n",
       "        answer = input(\"Your turn! Please respond with a question or statement that answers the prompt: \")\n",
       "        return answer\n",
       "\n",
       "    def chain_of_thought(self):\n",
       "        while True:\n",
       "            prompt = self.generate_prompt()\n",
       "            answer = self.ask_question(prompt)\n",
       "            print(f\"Your turn! Please respond with a question or statement that answers the prompt: {prompt}\")\n",
       "            print(f\"Your answer: {answer}\")\n",
       "            print()\n",
       "\n",
       "# Example usage:\n",
       "chain_of_thought = ChainOfThought()\n",
       "chain_of_thought.chain_of_thought()\n",
       "```\n",
       "\n",
       "This code defines a `ChainOfThought` class that contains a dictionary of questions and their corresponding answers. The `generate_prompt` method selects a random prompt from the dictionary, and the `ask_question` method asks the user to respond with a question or statement that answers the prompt. The `chain_of_thought` method generates a prompt, asks the user to respond, and then repeats the process until the user chooses to stop.\n",
       "\n",
       "You can add or remove questions and answers from the dictionary as needed. This code provides a basic structure for building a Chain of Thought prompt pattern using the OpenAI Python library."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JoSF5wb_Imw"
   },
   "source": [
    "## Task 4: Coding Tasks - SQL\n",
    "\n",
    "This prompt tests an LLM's capabilities for generating SQL code based on various tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XKGZIG3_Tjl"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in generating SQL code.\n",
    "\n",
    "Understand the following schema of the database tables carefully:\n",
    "Table departments, columns = [DepartmentId, DepartmentName]\n",
    "Table employees, columns = [EmployeeId, EmployeeName, DepartmentId]\n",
    "Table salaries, columns = [EmployeeId, Salary]\n",
    "\n",
    "Create a MySQL query for the employee with max salary in the 'IT' Department.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "4cFqsBtSA7Wx",
    "outputId": "c6a82832-0579-44e4-e5c8-ba403cefe446"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To find the employee with the maximum salary in the 'IT' department, you can use the following MySQL query:\n",
       "\n",
       "```sql\n",
       "SELECT E.EmployeeName\n",
       "FROM employees E\n",
       "JOIN departments D ON E.DepartmentId = D.DepartmentId\n",
       "WHERE D.DepartmentName = 'IT'\n",
       "ORDER BY E.Salary DESC\n",
       "LIMIT 1;\n",
       "```\n",
       "\n",
       "This query works as follows:\n",
       "\n",
       "1. It joins the `employees` table with the `departments` table on the `DepartmentId` column.\n",
       "2. It filters the results to only include employees in the 'IT' department.\n",
       "3. It orders the results in descending order by salary (highest salary first).\n",
       "4. Finally, it limits the results to a single row, which is the employee with the maximum salary in the 'IT' department.\n",
       "\n",
       "Note: If there are multiple employees with the same maximum salary in the 'IT' department, this query will return only one of them. If you want to return all employees with the maximum salary, you can use the following query:\n",
       "\n",
       "```sql\n",
       "SELECT E.EmployeeName\n",
       "FROM employees E\n",
       "JOIN departments D ON E.DepartmentId = D.DepartmentId\n",
       "WHERE D.DepartmentName = 'IT'\n",
       "ORDER BY E.Salary DESC\n",
       "LIMIT 1;\n",
       "```\n",
       "\n",
       "This query will return all employees with the maximum salary in the 'IT' department."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mck_SlcM3bG"
   },
   "source": [
    "## Task 5: Information Extraction\n",
    "\n",
    "This prompt tests an LLM's capabilities for extracting and analyzing key entities from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxciK2wsIw3U"
   },
   "outputs": [],
   "source": [
    "clinical_note = \"\"\"\n",
    "60-year-old man in NAD with a h/o CAD, DM2, asthma, pharyngitis, SBP,\n",
    "and HTN on altace for 8 years awoke from sleep around 1:00 am this morning\n",
    "with a sore throat and swelling of the tongue.\n",
    "He came immediately to the ED because he was having difficulty swallowing and\n",
    "some trouble breathing due to obstruction caused by the swelling.\n",
    "He did not have any associated SOB, chest pain, itching, or nausea.\n",
    "He has not noticed any rashes.\n",
    "He says that he feels like it is swollen down in his esophagus as well.\n",
    "He does not recall vomiting but says he might have retched a bit.\n",
    "In the ED he was given 25mg benadryl IV, 125 mg solumedrol IV,\n",
    "and pepcid 20 mg IV.\n",
    "Family history of CHF and esophageal cancer (father).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcazKzm0JGKc"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in analyzing and understanding clinical doctor notes in healthcare.\n",
    "Extract all symptoms only from the clinical note information below.\n",
    "Differentiate between symptoms that are present vs. absent.\n",
    "Give me the probability (high/ medium/ low) of how sure you are about the result.\n",
    "Add a note on the probabilities and why you think so.\n",
    "\n",
    "Output as a markdown table with the following columns,\n",
    "all symptoms should be expanded and no acronyms unless you don't know:\n",
    "\n",
    "Symptoms | Present/Denies | Probability.\n",
    "\n",
    "Also expand all acronyms.\n",
    "Output that also as a separate appendix table in Markdown.\n",
    "\n",
    "Clinical Note:\n",
    "```{clinical_note}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pqXCxmtEJl4h",
    "outputId": "b7558022-c109-4e16-e828-1622bd26fb64"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Symptoms Table**\n",
       "\n",
       "| Symptom | Present/Denies | Probability |\n",
       "| --- | --- | --- |\n",
       "| Sore throat | Present | High |\n",
       "| Swelling of the tongue | Present | High |\n",
       "| Difficulty swallowing | Present | High |\n",
       "| Trouble breathing due to obstruction | Present | High |\n",
       "| Swelling in the esophagus | Present | High |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies | Low |\n",
       "| Retching | Present | Medium |\n",
       "| SOB (Shortness of breath) | Denies | Low |\n",
       "| Chest pain | Denies | Low |\n",
       "| Itching | Denies | Low |\n",
       "| Nausea | Denies | Low |\n",
       "| Rashes | Denies | Low |\n",
       "| Vomiting | Denies |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jucY6L9w14Z"
   },
   "source": [
    "## Task 6: Closed-Domain Question Answering\n",
    "\n",
    "Question Answering (QA) is a natural language processing task which involves generating the desired answer for the given question. Question Answering can be open-domain QA or closed-domain QA depending on whether the LLM is provided with the relevant context or not.\n",
    "\n",
    "In the case of closed-domain QA, a question along with relevant context is given. Here the context is nothing but the relevant text which ideally should have the answer. Just like a RAG workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I7ZsP3OxL-n"
   },
   "outputs": [],
   "source": [
    "report = \"\"\"\n",
    "Three quarters (77%) of the population saw an increase in their regular outgoings over the past year,\n",
    "according to findings from our recent consumer survey. In contrast, just over half (54%) of respondents\n",
    "had an increase in their salary, which suggests that the burden of costs outweighing income remains for\n",
    "most. In total, across the 2,500 people surveyed, the increase in outgoings was 18%, three times higher\n",
    "than the 6% increase in income.\n",
    "\n",
    "Despite this, the findings of our survey suggest we have reached a plateau. Looking at savings,\n",
    "for example, the share of people who expect to make regular savings this year is just over 70%,\n",
    "broadly similar to last year. Over half of those saving plan to use some of the funds for residential\n",
    "property. A third are saving for a deposit, and a further 20% for an investment property or second home.\n",
    "\n",
    "But for some, their plans are being pushed back. 9% of respondents stated they had planned to purchase\n",
    "a new home this year but have now changed their mind. While for many the deposit may be an issue,\n",
    "the other driving factor remains the cost of the mortgage, which has been steadily rising the last\n",
    "few years. For those that currently own a property, the survey showed that in the last year,\n",
    "the average mortgage payment has increased from ¬£668.51 to ¬£748.94, or 12%.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAPf8hD2xATM"
   },
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "How much has the average mortage payment increased in the last year?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Using the following context information below please answer the following question\n",
    "to the best of your ability\n",
    "Context:\n",
    "{report}\n",
    "Question:\n",
    "{question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "whY2mBoXxUPM",
    "outputId": "6238b078-2209-495b-a3ef-0052e5757dc1"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The average mortgage payment has increased from ¬£668.51 to ¬£748.94, which is an increase of ¬£80.43."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "A-Dxn9d_xibD",
    "outputId": "eeae61db-6913-4d9f-fdd4-49c732bd4a7b"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "54%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "What percentage of people had an increase in salary last year? Show the answer just as a number.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Using the following context information below please answer the following question\n",
    "to the best of your ability\n",
    "Context:\n",
    "{report}\n",
    "Question:\n",
    "{question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuQlsSmWxyCd"
   },
   "source": [
    "## Task 7: Open-Domain Question Answering\n",
    "\n",
    "Question Answering (QA) is a natural language processing task which involves generating the desired answer for the given question.\n",
    "\n",
    "In the case of open-domain QA, only the question is asked without providing any context or information. Here, the LLM answers the question using the knowledge gained from large volumes of text data during its training. This is basically Zero-Shot QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fV2MP4OdyETp"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Please answer the following question to the best of your ability\n",
    "Question:\n",
    "What is LangChain?\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "OSC-IhDmyRYg",
    "outputId": "20d697e8-99bc-477e-8748-944fe47cb96f"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LangChain is a decentralized, open-source, and community-driven project that aims to create a more secure and transparent blockchain. It is a fork of the existing Hyperledger Fabric blockchain platform, with the goal of improving its scalability, security, and usability.\n",
       "\n",
       "LangChain is designed to be more flexible and adaptable than traditional blockchain platforms, allowing it to be used for a wide range of applications, including supply chain management, identity verification, and more. The project is led by a community of developers and researchers who are committed to making LangChain a viable and practical solution for real-world use cases.\n",
       "\n",
       "LangChain's key features include:\n",
       "\n",
       "1. Improved scalability: LangChain is designed to be more scalable than traditional blockchain platforms, allowing it to handle a larger number of transactions per second.\n",
       "2. Enhanced security: LangChain incorporates advanced security measures, including encryption, access controls, and smart contract functionality.\n",
       "3. Increased usability: LangChain is designed to be more user-friendly than traditional blockchain platforms, with a focus on simplicity and ease of use.\n",
       "\n",
       "Overall, LangChain is an innovative project that is pushing the boundaries of what is possible with blockchain technology. Its focus on scalability, security, and usability makes it an attractive option for a wide range of use cases."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMX1CcsdMg_C"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Please answer the following question to the best of your ability\n",
    "Question:\n",
    "What is LangGraph?\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "8-AxYD5AMjk6",
    "outputId": "cda370c8-975e-46f4-ab98-50d2b81ce2c2"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LangGraph is a graph database that provides a scalable and flexible way to store and query graph data. It is designed to handle large-scale graph processing and analysis workloads, making it suitable for applications such as social network analysis, recommendation systems, and knowledge graph construction.\n",
       "\n",
       "LangGraph is built on top of a distributed graph database, allowing it to scale horizontally and handle high volumes of data. It provides a range of features, including graph data types, node and edge attributes, and query capabilities, making it a popular choice for graph data analysis and processing.\n",
       "\n",
       "LangGraph is also known for its support for various graph algorithms and data structures, including graph traversals, shortest paths, and clustering. Additionally, it provides a flexible data model that allows users to define their own graph data types and attributes, making it a versatile tool for a wide range of applications.\n",
       "\n",
       "Overall, LangGraph is a powerful and flexible graph database that is well-suited for large-scale graph processing and analysis workloads."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnVmXCZAzyux"
   },
   "source": [
    "## Task 8: Document Summarization\n",
    "\n",
    "Document summarization is a natural language processing task which involves creating a concise summary of the given text, while still capturing all the important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dY53sXf_ymwE"
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "Coronaviruses are a large family of viruses which may cause illness in animals or humans.\n",
    "In humans, several coronaviruses are known to cause respiratory infections ranging from the\n",
    "common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS).\n",
    "The most recently discovered coronavirus causes coronavirus disease COVID-19.\n",
    "COVID-19 is the infectious disease caused by the most recently discovered coronavirus.\n",
    "This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n",
    "COVID-19 is now a pandemic affecting many countries globally.\n",
    "The most common symptoms of COVID-19 are fever, dry cough, and tiredness.\n",
    "Other symptoms that are less common and may affect some patients include aches\n",
    "and pains, nasal congestion, headache, conjunctivitis, sore throat, diarrhea,\n",
    "loss of taste or smell or a rash on skin or discoloration of fingers or toes.\n",
    "These symptoms are usually mild and begin gradually.\n",
    "Some people become infected but only have very mild symptoms.\n",
    "Most people (about 80%) recover from the disease without needing hospital treatment.\n",
    "Around 1 out of every 5 people who gets COVID-19 becomes seriously ill and develops difficulty breathing.\n",
    "Older people, and those with underlying medical problems like high blood pressure, heart and lung problems,\n",
    "diabetes, or cancer, are at higher risk of developing serious illness.\n",
    "However, anyone can catch COVID-19 and become seriously ill.\n",
    "People of all ages who experience fever and/or  cough associated with difficulty breathing/shortness of breath,\n",
    "chest pain/pressure, or loss of speech or movement should seek medical attention immediately.\n",
    "If possible, it is recommended to call the health care provider or facility first,\n",
    "so the patient can be directed to the right clinic.\n",
    "People can catch COVID-19 from others who have the virus.\n",
    "The disease spreads primarily from person to person through small droplets from the nose or mouth,\n",
    "which are expelled when a person with COVID-19 coughs, sneezes, or speaks.\n",
    "These droplets are relatively heavy, do not travel far and quickly sink to the ground.\n",
    "People can catch COVID-19 if they breathe in these droplets from a person infected with the virus.\n",
    "This is why it is important to stay at least 1 meter) away from others.\n",
    "These droplets can land on objects and surfaces around the person such as tables, doorknobs and handrails.\n",
    "People can become infected by touching these objects or surfaces, then touching their eyes, nose or mouth.\n",
    "This is why it is important to wash your hands regularly with soap and water or clean with alcohol-based hand rub.\n",
    "Practicing hand and respiratory hygiene is important at ALL times and is the best way to protect others and yourself.\n",
    "When possible maintain at least a 1 meter distance between yourself and others.\n",
    "This is especially important if you are standing by someone who is coughing or sneezing.\n",
    "Since some infected persons may not yet be exhibiting symptoms or their symptoms may be mild,\n",
    "maintaining a physical distance with everyone is a good idea if you are in an area where COVID-19 is circulating.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "id": "7upxVwh5y8te",
    "outputId": "4f7c76ed-f896-4923-aed6-1fd2f48fcb18"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Summary:\n",
       "Coronaviruses are a large family of viruses that can cause illness in both animals and humans. COVID-19, the most recently discovered coronavirus, is a severe respiratory disease that affects many countries globally. Symptoms include fever, dry cough, and tiredness, with some people experiencing mild or severe illness. The disease spreads primarily through small droplets from the nose or mouth, and proper hand hygiene is crucial to prevent infection. Maintaining a physical distance of at least 1 meter from others is also essential to protect both individuals and those around them."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an expert in generating accurate document summaries.\n",
    "Generate a summary of the given document.\n",
    "\n",
    "Document:\n",
    "{doc}\n",
    "\n",
    "\n",
    "Constraints: Please start the summary with the delimiter 'Summary'\n",
    "and limit the summary to 5 lines\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keC5k5S-18cw"
   },
   "source": [
    "## Task 9: Transformation\n",
    "\n",
    "You can use LLMs to take an existing document and transform it into other formats of content and even generate training data for fine-tuning or training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ta182I2t2FD0"
   },
   "outputs": [],
   "source": [
    "fact_sheet_mobile = \"\"\"\n",
    "PRODUCT NAME\n",
    "Samsung Galaxy Z Fold4 5G Black\n",
    "‚Äã\n",
    "PRODUCT OVERVIEW\n",
    "Stands out. Stands up. Unfolds.\n",
    "The Galaxy Z Fold4 does a lot in one hand with its 15.73 cm(6.2-inch) Cover Screen.\n",
    "Unfolded, the 19.21 cm(7.6-inch) Main Screen lets you really get into the zone.\n",
    "Pushed-back bezels and the Under Display Camera means there's more screen\n",
    "and no black dot getting between you and the breathtaking Infinity Flex Display.\n",
    "Do more than more with Multi View. Whether toggling between texts or catching up\n",
    "on emails, take full advantage of the expansive Main Screen with Multi View.\n",
    "PC-like power thanks to Qualcomm Snapdragon 8+ Gen 1 processor in your pocket,\n",
    "transforms apps optimized with One UI to give you menus and more in a glance\n",
    "New Taskbar for PC-like multitasking. Wipe out tasks in fewer taps. Add\n",
    "apps to the Taskbar for quick navigation and bouncing between windows when\n",
    "you're in the groove.4 And with App Pair, one tap launches up to three apps,\n",
    "all sharing one super-productive screen\n",
    "Our toughest Samsung Galaxy foldables ever. From the inside out,\n",
    "Galaxy Z Fold4 is made with materials that are not only stunning,\n",
    "but stand up to life's bumps and fumbles. The front and rear panels,\n",
    "made with exclusive Corning Gorilla Glass Victus+, are ready to resist\n",
    "sneaky scrapes and scratches. With our toughest aluminum frame made with\n",
    "Armor Aluminum, this is one durable smartphone.\n",
    "World‚Äôs first water resistant foldable smartphones. Be adventurous, rain\n",
    "or shine. You don't have to sweat the forecast when you've got one of the\n",
    "world's first water-resistant foldable smartphones.\n",
    "‚Äã\n",
    "PRODUCT SPECS\n",
    "OS - Android 12.0\n",
    "RAM - 12 GB\n",
    "Product Dimensions - 15.5 x 13 x 0.6 cm; 263 Grams\n",
    "Batteries - 2 Lithium Ion batteries required. (included)\n",
    "Item model number - SM-F936BZKDINU_5\n",
    "Wireless communication technologies - Cellular\n",
    "Connectivity technologies - Bluetooth, Wi-Fi, USB, NFC\n",
    "GPS - True\n",
    "Special features - Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, Water Resistant\n",
    "Other display features - Wireless\n",
    "Device interface - primary - Touchscreen\n",
    "Resolution - 2176x1812\n",
    "Other camera features - Rear, Front\n",
    "Form factor - Foldable Screen\n",
    "Colour - Phantom Black\n",
    "Battery Power Rating - 4400\n",
    "Whats in the box - SIM Tray Ejector, USB Cable\n",
    "Manufacturer - Samsung India pvt Ltd\n",
    "Country of Origin - China\n",
    "Item Weight - 263 g\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "zko53u-N2KmD",
    "outputId": "2ce73bf9-a358-4393-ffcd-a68ef5b7bb20"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the FAQs based on the product description:\n",
       "\n",
       "**Q1: What is the display size of the Samsung Galaxy Z Fold4 5G Black?**\n",
       "A1: The display size of the Samsung Galaxy Z Fold4 5G Black is 19.21 cm (7.6-inch) for the Main Screen and 15.73 cm (6.2-inch) for the Cover Screen.\n",
       "\n",
       "**Q2: What is the resolution of the display?**\n",
       "A2: The resolution of the display is 2176x1812.\n",
       "\n",
       "**Q3: What is the battery life of the Samsung Galaxy Z Fold4 5G Black?**\n",
       "A3: The battery life of the Samsung Galaxy Z Fold4 5G Black is 4400.\n",
       "\n",
       "**Q4: What is the processor used in the Samsung Galaxy Z Fold4 5G Black?**\n",
       "A4: The processor used in the Samsung Galaxy Z Fold4 5G Black is Qualcomm Snapdragon 8+ Gen 1.\n",
       "\n",
       "**Q5: What is the camera resolution of the Samsung Galaxy Z Fold4 5G Black?**\n",
       "A5: The camera resolution of the Samsung Galaxy Z Fold4 5G Black is Rear: 50MP, Front: 32MP.\n",
       "\n",
       "**Q6: What is the durability of the Samsung Galaxy Z Fold4 5G Black?**\n",
       "A6: The Samsung Galaxy Z Fold4 5G Black is made with materials that are not only stunning but also resistant to life's bumps and fumbles, including the front and rear panels made with exclusive Corning Gorilla Glass Victus+ and the toughest aluminum frame made with Armor Aluminum.\n",
       "\n",
       "**Q7: What is the water resistance of the Samsung Galaxy Z Fold4 5G Black?**\n",
       "A7: The Samsung Galaxy Z Fold4 5G Black is water resistant, with a rating of World's first water resistant foldable smartphones.\n",
       "\n",
       "**Q8: What is the price of the Samsung Galaxy Z Fold4 5G Black?**\n",
       "A8: The price of the Samsung Galaxy Z Fold4 5G Black is not specified in the provided information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt =f\"\"\"Turn the following product description into a list of frequently asked questions (FAQ).\n",
    "Show both the question and it's corresponding answer.\n",
    "Create at the max 8 FAQs\n",
    "\n",
    "Product description:\n",
    "```{fact_sheet_mobile}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53QdnJ0M3Vee"
   },
   "source": [
    "## Task 10: Translation\n",
    "\n",
    "You can use LLMs to take an existing document and translate it from a source to target language. You can also translate to multiple languages at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "g-jdFJqJ2cWu",
    "outputId": "5d738bcf-785e-4bca-ebe4-36b3c234d1ad"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the translations:\n",
       "\n",
       "- English: \"Hello, how are you today?\"\n",
       "- German: \"Hallo, wie geht es dir heute?\"\n",
       "- Spanish: \"Hola, ¬øc√≥mo est√°s hoy?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are an expert translator.\n",
    "Translate the given text from English to German and Spanish.\n",
    "\n",
    "Text: 'Hello, how are you today?'\n",
    "Translation:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
