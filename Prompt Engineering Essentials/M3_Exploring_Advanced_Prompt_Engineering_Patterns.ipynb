{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTzBUFWQ-OWj"
      },
      "source": [
        "# Exploring Advanced Prompt Engineering Patterns\n",
        "\n",
        "In this notebook you will use ChatGPT and LangChain to learn about:\n",
        "\n",
        "- Chain of Thought Pattern\n",
        "- Self-Consistency Pattern\n",
        "- Least to Most Pattern\n",
        "- ReAct Pattern\n",
        "\n",
        "___Created By: Dipanjan (DJ)___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI and LangChain dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eEzecGfICCw1",
        "outputId": "7e61b7a6-45ce-4462-b82f-10022137d630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.10\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (2.0.43)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (3.12.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (0.3.11)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.10)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (2.0.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (2.11.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.10) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.20.1)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.4.0,>=0.3.22 (from langchain==0.3.10)\n",
            "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.73-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (1.33)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (4.15.0)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.10)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.0.0)\n",
            "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pip>=25.2 (from langchain-text-splitters<0.4.0,>=0.3.0->langchain==0.3.10)\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.10)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.10) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.10) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.10) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.10) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.10) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.3.1)\n",
            "Downloading langchain-0.3.10-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.28\n",
            "    Uninstalling langsmith-0.4.28:\n",
            "      Successfully uninstalled langsmith-0.4.28\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.76\n",
            "    Uninstalling langchain-core-0.3.76:\n",
            "      Successfully uninstalled langchain-core-0.3.76\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed langchain-0.3.10 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langsmith-0.1.147 packaging-24.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              },
              "id": "065d9f761b7b462aaf5fc8ccdaf947b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai==0.2.12\n",
            "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.12) (0.3.63)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.12) (1.108.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.12) (0.11.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.1.147)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.15.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.11.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.5.0)\n",
            "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.2.12\n",
            "Collecting langchain-community==0.3.30\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-core<2.0.0,>=0.3.75 (from langchain-community==0.3.30)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting langchain<2.0.0,>=0.3.27 (from langchain-community==0.3.30)\n",
            "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community==0.3.30)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community==0.3.30)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (0.1.147)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.30) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.30) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.30) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.30) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.30) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.30) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.30) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.30) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.3.30)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.3.30)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<2.0.0,>=0.3.27->langchain-community==0.3.30)\n",
            "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community==0.3.30) (2.11.9)\n",
            "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community==0.3.30)\n",
            "  Downloading langsmith-0.4.31-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community==0.3.30) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community==0.3.30) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community==0.3.30) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.3.30) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.3.30) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community==0.3.30) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community==0.3.30) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community==0.3.30) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community==0.3.30) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community==0.3.30) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community==0.3.30) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community==0.3.30) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community==0.3.30) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.3.30)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community==0.3.30) (1.3.1)\n",
            "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.4.31-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.3/386.3 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.147\n",
            "    Uninstalling langsmith-0.1.147:\n",
            "      Successfully uninstalled langsmith-0.1.147\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.63\n",
            "    Uninstalling langchain-core-0.3.63:\n",
            "      Successfully uninstalled langchain-core-0.3.63\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.8\n",
            "    Uninstalling langchain-text-splitters-0.3.8:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.10\n",
            "    Uninstalling langchain-0.3.10:\n",
            "      Successfully uninstalled langchain-0.3.10\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-0.3.27 langchain-community-0.3.30 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.31 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Collecting ddgs==9.6.0\n",
            "  Downloading ddgs-9.6.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs==9.6.0) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from ddgs==9.6.0)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting lxml>=6.0.0 (from ddgs==9.6.0)\n",
            "  Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (1.1.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs==9.6.0) (4.15.0)\n",
            "Downloading ddgs-9.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: socksio, primp, lxml, ddgs\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 5.4.0\n",
            "    Uninstalling lxml-5.4.0:\n",
            "      Successfully uninstalled lxml-5.4.0\n",
            "Successfully installed ddgs-9.6.0 lxml-6.0.2 primp-0.15.0 socksio-1.0.0\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.10\n",
        "!pip install langchain-openai==0.2.12\n",
        "!pip install langchain-community==0.3.30\n",
        "!pip install ddgs==9.6.0\n",
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwGjVWK4q6F"
      },
      "source": [
        "## Load OpenAI API Credentials\n",
        "\n",
        "Here we load it from get password function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtBa7rlWJWH3"
      },
      "source": [
        "## Enter API Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ogxBkS6ZnnC"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDe44J0N0NcC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDWhgxCy5bA6"
      },
      "source": [
        "## Load Necessary Dependencies and ChatGPT LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY2bapqfuWq1"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvjOf7W_v35E"
      },
      "source": [
        "## Chain-of-Thought (CoT) Pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7GyfJf_srzS"
      },
      "source": [
        "### Zero Shot CoT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "zW1h6eeEv57r",
        "outputId": "e96ae4cd-3de4-4b78-cd2b-73a8d8dca849"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To determine the shortest valid field goal in the game details provided, we need to analyze the information step-by-step.\n\n1. **Understanding Field Goals**: A field goal in American football is a scoring play where the ball is kicked through the opponent's goalposts. The distance of a field goal is measured from the line of scrimmage to the goalposts, plus an additional 10 yards for the end zone.\n\n2. **Identifying Field Goals in the Game**:\n   - The first field goal mentioned is a **35-yard field goal** made by Shaun Suisham.\n   - The second field goal attempt is a **31-yard field goal**, but it was blocked and therefore does not count as a valid field goal.\n\n3. **Determining Valid Field Goals**: \n   - A valid field goal is one that is successfully kicked through the goalposts. In this case, the only successful field goal mentioned is the 35-yard field goal.\n\n4. **Conclusion**: Since the only successful field goal in the game was the 35-yard field goal, and the blocked attempt does not count, we conclude that the shortest valid field goal is the one that was made.\n\nThus, the answer is:\n\n**35 yards**."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "prompt = \"\"\"Given the following game details,\n",
        "            How many yards was the shortest valid field goal?\n",
        "            Think step-by-step to get to your answer.\n",
        "            Show your step-by-step reasoning and then the answer.\n",
        "\n",
        "            Coming off their win over the Broncos, the Redskins flew to Cowboys Stadium\n",
        "            for their Week 11 NFC East rivalry match against the Dallas Cowboys.\n",
        "            After a scoreless first quarter, Washington would strike in the second quarter\n",
        "            as kicker Shaun Suisham nailed a 35-yard field goal.\n",
        "            The Redskins would try to add onto their lead in the third quarter\n",
        "            with Suisham booting a 31-yard field goal which was blocked.\n",
        "            However, in the fourth quarter, the Cowboys rallied as quarterback Tony Romo\n",
        "            completing a 10-yard touchdown pass to wide receiver Patrick Crayton.\n",
        "         \"\"\"\n",
        "\n",
        "response = chatgpt.invoke(prompt)\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS-RDO8jFqqM"
      },
      "source": [
        "### Few-Shot CoT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0HnrM2SFqqM",
        "outputId": "fdfa982e-e95f-42b8-b11c-0e9c1f3937b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To determine the shortest valid field goal from the game details provided, we need to analyze the information step-by-step.\n",
            "\n",
            "Reasoning:\n",
            "Step 1: The first field goal mentioned is a 35-yard field goal made by Shaun Suisham in the second quarter.\n",
            "Step 2: The second field goal attempt is a 31-yard field goal by Suisham in the third quarter, but this attempt was blocked and therefore does not count as a valid field goal.\n",
            "Step 3: Since the only valid field goal mentioned is the 35-yard field goal, we need to identify if there are any other field goals mentioned in the details. However, there are no other field goals provided in the text.\n",
            "Step 4: The shortest valid field goal is the only one that was successfully made, which is the 35-yard field goal.\n",
            "\n",
            "A: 35 yards\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "prompt = \"\"\"Given the following game details,\n",
        "            How many yards was the shortest valid field goal?\n",
        "            Think step-by-step to get to your answer similar to the following examples:\n",
        "\n",
        "            Example 1:\n",
        "            Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
        "               Each can has 3 tennis balls. How many tennis balls does he have now?\n",
        "\n",
        "            Reasoning:\n",
        "              Step 1: Roger started with 5 balls.\n",
        "              Step 2: 2 cans of 3 tennis balls each is 6 tennis balls in total.\n",
        "              Step 3: 5 + 6 = 11 tennis balls.\n",
        "\n",
        "            A: 11 Tennis Balls\n",
        "\n",
        "            Example 2:\n",
        "            Q: How many keystrokes are needed to type the numbers from 1 to 500?\n",
        "\n",
        "            Reasoning:\n",
        "              Step 1: There are 9 one-digit numbers from 1 to 9.\n",
        "              Step 2: There are 90 two-digit numbers from 10 to 99.\n",
        "              Step 3: There are 401 three-digit numbers from 100 to 500.\n",
        "              Step 4: Adding all of them up, 9 + 90 + 401 = 1392 keystrokes.\n",
        "\n",
        "            A: 1392 keystrokes\n",
        "\n",
        "\n",
        "            Q: Coming off their win over the Broncos, the Redskins flew to Cowboys Stadium\n",
        "            for their Week 11 NFC East rivalry match against the Dallas Cowboys.\n",
        "            After a scoreless first quarter, Washington would strike in the second quarter\n",
        "            as kicker Shaun Suisham nailed a 35-yard field goal.\n",
        "            The Redskins would try to add onto their lead in the third quarter\n",
        "            with Suisham booting a 31-yard field goal which was blocked.\n",
        "            However, in the fourth quarter, the Cowboys rallied as quarterback Tony Romo\n",
        "            completing a 10-yard touchdown pass to wide receiver Patrick Crayton.\n",
        "         \"\"\"\n",
        "\n",
        "response = chatgpt.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgxPaWv_MiqF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kcqGa4kMi7l"
      },
      "source": [
        "## Self-Consistency Pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH1IZD6PMi7l",
        "outputId": "aca68619-f9a4-4197-9c4e-fa1ba60c5419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Given the following problem,\n",
            "                    Think step-by-step to get to your answer similar to the following example:\n",
            "\n",
            "                    Example 1:\n",
            "                    Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
            "                    Each can has 3 tennis balls. How many tennis balls does he have now?\n",
            "\n",
            "                    Reasoning:\n",
            "                    Step 1: Roger started with 5 balls.\n",
            "                    Step 2: 2 cans of 3 tennis balls each is 6 tennis balls in total.\n",
            "                    Step 3: 5 + 6 = 11 tennis balls.\n",
            "\n",
            "                    A: 11 Tennis Balls\n",
            "\n",
            "                    Problem:\n",
            "                    \u001b[33;1m\u001b[1;3m{problem}\u001b[0m\n",
            "                \n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "cot_prompt_txt = \"\"\"Given the following problem,\n",
        "                    Think step-by-step to get to your answer similar to the following example:\n",
        "\n",
        "                    Example 1:\n",
        "                    Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
        "                    Each can has 3 tennis balls. How many tennis balls does he have now?\n",
        "\n",
        "                    Reasoning:\n",
        "                    Step 1: Roger started with 5 balls.\n",
        "                    Step 2: 2 cans of 3 tennis balls each is 6 tennis balls in total.\n",
        "                    Step 3: 5 + 6 = 11 tennis balls.\n",
        "\n",
        "                    A: 11 Tennis Balls\n",
        "\n",
        "                    Problem:\n",
        "                    {problem}\n",
        "                \"\"\"\n",
        "\n",
        "cot_prompt = ChatPromptTemplate.from_template(cot_prompt_txt)\n",
        "cot_prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN1SckLsNrox",
        "outputId": "76324ddd-f422-4cd4-9244-4c43eb41ce3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Given the following problem\n",
            "                         and 3 diverse reasoning paths explored by an AI model\n",
            "                         analyse these pathways carefully,\n",
            "                         aggregate, take the majority vote as needed\n",
            "                         and generate a final single reasoning path along with the answer\n",
            "\n",
            "                         AI Model Reasoning Path 1:\n",
            "                         \u001b[33;1m\u001b[1;3m{reasoning_path_1}\u001b[0m\n",
            "\n",
            "                         AI Model Reasoning Path 2:\n",
            "                         \u001b[33;1m\u001b[1;3m{reasoning_path_2}\u001b[0m\n",
            "\n",
            "                         AI Model Reasoning Path 3:\n",
            "                         \u001b[33;1m\u001b[1;3m{reasoning_path_3}\u001b[0m\n",
            "\n",
            "                         Problem:\n",
            "                         \u001b[33;1m\u001b[1;3m{problem}\u001b[0m\n",
            "                    \n"
          ]
        }
      ],
      "source": [
        "self_con_prompt_txt = \"\"\"Given the following problem\n",
        "                         and 3 diverse reasoning paths explored by an AI model\n",
        "                         analyse these pathways carefully,\n",
        "                         aggregate, take the majority vote as needed\n",
        "                         and generate a final single reasoning path along with the answer\n",
        "\n",
        "                         AI Model Reasoning Path 1:\n",
        "                         {reasoning_path_1}\n",
        "\n",
        "                         AI Model Reasoning Path 2:\n",
        "                         {reasoning_path_2}\n",
        "\n",
        "                         AI Model Reasoning Path 3:\n",
        "                         {reasoning_path_3}\n",
        "\n",
        "                         Problem:\n",
        "                         {problem}\n",
        "                    \"\"\"\n",
        "\n",
        "self_con_prompt = ChatPromptTemplate.from_template(self_con_prompt_txt)\n",
        "self_con_prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhrBicOHNgtg"
      },
      "outputs": [],
      "source": [
        "# do CoT exploration independently 3 times with these models\n",
        "gpt1 = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
        "gpt2 = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.5)\n",
        "gpt3 = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIOdfK0xOwyx"
      },
      "outputs": [],
      "source": [
        "# do final reasoning and aggregation with this model\n",
        "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8f8hdCFOi1-"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "# independent CoT explorations with 3 different LLMs (with different temp settings)\n",
        "llm_chain1 = cot_prompt | gpt1 | StrOutputParser()\n",
        "llm_chain2 = cot_prompt | gpt2 | StrOutputParser()\n",
        "llm_chain3 = cot_prompt | gpt3 | StrOutputParser()\n",
        "\n",
        "sc_chain = (\n",
        "                RunnableParallel(problem=RunnablePassthrough(),\n",
        "                                 reasoning_path_1=llm_chain1,\n",
        "                                 reasoning_path_2=llm_chain2,\n",
        "                                 reasoning_path_3=llm_chain3)\n",
        "                        |\n",
        "                self_con_prompt\n",
        "                        |\n",
        "                    chatgpt\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USIGTgvvNLbC"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"Q: Coming off their win over the Broncos, the Redskins flew to Cowboys Stadium\n",
        "            for their Week 11 NFC East rivalry match against the Dallas Cowboys.\n",
        "            After a scoreless first quarter, Washington would strike in the second quarter\n",
        "            as kicker Shaun Suisham nailed a 35-yard field goal.\n",
        "            The Redskins would try to add onto their lead in the third quarter\n",
        "            with Suisham booting a 31-yard field goal which was blocked.\n",
        "            However, in the fourth quarter, the Cowboys rallied as quarterback Tony Romo\n",
        "            completing a 10-yard touchdown pass to wide receiver Patrick Crayton.\n",
        "            How many yards was the shortest valid field goal?\n",
        "           \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "U2IIjPhLQuCD",
        "outputId": "80381195-18e7-4944-9c0f-c677c5f5e06c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To generate a final reasoning path based on the three provided AI model reasoning paths, we will analyze the key points made in each path and aggregate them to form a cohesive conclusion.\n\n### Aggregated Reasoning Path:\n\n1. **Identification of Field Goals**: The problem states that Shaun Suisham made a successful 35-yard field goal in the second quarter. This is confirmed by all three reasoning paths.\n\n2. **Blocked Field Goal Attempt**: The problem also mentions a 31-yard field goal attempt by Suisham in the third quarter, which was blocked. All three paths correctly identify that a blocked field goal does not count as a valid field goal.\n\n3. **Determining Valid Field Goals**: The only valid field goal mentioned in the problem is the 35-yard field goal. The reasoning across all paths consistently concludes that there are no other valid field goals to consider.\n\n4. **Conclusion on Shortest Valid Field Goal**: Since the only successful field goal is the 35-yard one, it is also the shortest valid field goal. All paths arrive at the same conclusion regarding the shortest valid field goal.\n\n### Final Reasoning Path:\n- The problem describes a successful 35-yard field goal made by Shaun Suisham in the second quarter. It also mentions a 31-yard field goal attempt in the third quarter that was blocked, which does not count as valid. Therefore, the only valid field goal is the 35-yard one. Since there are no other valid field goals mentioned, the shortest valid field goal is 35 yards.\n\n### Final Answer:\n**35 yards**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = sc_chain.invoke({'problem': question})\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmmg7blAvcAt"
      },
      "source": [
        "## Least to Most Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QePjecVqviA3",
        "outputId": "f9e320ab-b35b-4110-a99e-adb78e2bfd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down this problem into subproblems:\n",
            "\n",
            "1. What were the valid field goals attempted in the game?\n",
            "2. How many yards was the shortest valid field goal?\n",
            "\n",
            "Now, let's analyze each subproblem:\n",
            "\n",
            "1. The valid field goals mentioned in the game are:\n",
            "   - Shaun Suisham's successful 35-yard field goal.\n",
            "   - A 31-yard field goal attempt by Suisham that was blocked, which does not count as a valid field goal since it was not successful.\n",
            "\n",
            "2. The only successful field goal is the 35-yard field goal. Since there is only one valid field goal, it is also the shortest.\n",
            "\n",
            "A: The final answer is 35 yards.\n"
          ]
        }
      ],
      "source": [
        "PROMPT = \"\"\"You are a strong reasoning agent.\n",
        "            Respond to user question with concise and helpful information.\n",
        "            Follow the format as mentioned in the example,\n",
        "            break down the problem first into sub problems,\n",
        "            answer each sub problem sequentially, analyze it\n",
        "            and then get to the final answer.\n",
        "            Do not jump directly to the answer\n",
        "\n",
        "            Example:\n",
        "\n",
        "            Q: Against Tim Tebow and the Broncos, the two teams would be in a 0-0 deadlock\n",
        "            in the first half, though the Broncos would nearly score in the second quarter\n",
        "            on a 28-yard field goal, which would then be blocked by Julius Peppers.\n",
        "            The Bears would then score 10 points on Marion Barber's 9-yard touchdown run,\n",
        "            and Robbie Gould's team record-breaking 57-yard field goal, but Tebow's touchdown pass\n",
        "            to Demaryius Thomas and Matt Prater's 59-yard field goal would tie the game.\n",
        "            Barber would commit two costly mistakes during the late portion of the game.\n",
        "            In the fourth quarter, Barber would run out of bounds with 1:55 left,\n",
        "            and Barber would also fumble in overtime.\n",
        "            The Broncos would then move downfield and kick a game-winning field goal.\n",
        "            How many yards was the games longest field goal?\n",
        "\n",
        "            Response:\n",
        "            Let's break down this problem into subproblems:\n",
        "              1. What were the field goals when field goal was?\n",
        "              2. How many yards was the games longest field goal?\n",
        "\n",
        "            The answer to subproblems are as follows:\n",
        "              1. The field goals were 28-yard,  57-yard and  59-yard which are all valid goals\n",
        "              2. The maximum value out of  59-yard, 28-yard and 57-yard is 59\n",
        "\n",
        "            A: The final answer is 59 yards.\n",
        "\n",
        "            Question:\n",
        "            {query}\n",
        "        \"\"\"\n",
        "\n",
        "query = \"\"\"Coming off their win over the Broncos, the Redskins flew to Cowboys Stadium\n",
        "           for their Week 11 NFC East rivalry match against the Dallas Cowboys.\n",
        "           After a scoreless first quarter, Washington would strike in the second quarter\n",
        "           as kicker Shaun Suisham nailed a 35-yard field goal.\n",
        "           The Redskins would try to add onto their lead in the third quarter\n",
        "           with Suisham booting a 31-yard field goal which was blocked.\n",
        "           However, in the fourth quarter, the Cowboys rallied as quarterback Tony Romo\n",
        "           completing a 10-yard touchdown pass to wide receiver Patrick Crayton.\n",
        "           How many yards was the shortest valid field goal?\n",
        "        \"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(PROMPT)\n",
        "\n",
        "chain = (prompt\n",
        "           |\n",
        "         chatgpt\n",
        ")\n",
        "\n",
        "response = chain.invoke({\"query\": query})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op_BboJFoXg5"
      },
      "source": [
        "## ReAct Prompting - Agentic AI Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "7GsAHiKvoXg5",
        "outputId": "28e52638-8325-4bde-b79b-a6d89bc41ffb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "As of my last knowledge update in October 2023, there is no widely recognized tool or framework specifically named \"LangGraph.\" It's possible that it could refer to a new project, library, or concept that has emerged after that date, or it may be a niche tool that hasn't gained significant attention in mainstream discussions.\n\nIf you have specific details or context about LangGraph, such as its purpose or the domain it operates in, I could help you better understand related concepts or technologies. Otherwise, I recommend checking the latest resources or official documentation for the most accurate and up-to-date information."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"Tell me about LangGraph in detail including who made it and key features.\n",
        "            Do not make up answers, only answer if you are sure\"\"\"\n",
        "\n",
        "# it will either not answer or end up hallucinating the answer\n",
        "response = chatgpt.invoke(prompt)\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm1cOqAnoks4"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "from langchain_core.tools import tool\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web for a query.\"\"\"\n",
        "    print('Searching web and extracting page info')\n",
        "    wrapper = DuckDuckGoSearchAPIWrapper(max_results=5)\n",
        "    results = wrapper.results(query, max_results=5)\n",
        "    docs = []\n",
        "    for result in tqdm(results):\n",
        "        try:\n",
        "            response = requests.get(result['link'])\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            text_content = soup.get_text(separator=\"\\n\", strip=True)\n",
        "            docs.append(text_content)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {result['link']}: {e}\")\n",
        "        time.sleep(2)\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBI_GNDJqVbE",
        "outputId": "ab8e4131-a125-46ae-fb5c-88676caf9dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2017995428.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  r = search_web('What is langgraph')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching web and extracting page info\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.97s/it]\n"
          ]
        }
      ],
      "source": [
        "r = search_web('What is langgraph')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvd0qJn6qW3a",
        "outputId": "d343a690-ddea-441e-c035-d642765abb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is LangGraph? | IBM\n",
            "What is LangGraph?\n",
            "AI Agents\n",
            "Welcome\n",
            "Caret right\n",
            "Introduction\n",
            "Overview\n",
            "AI agents vs AI assistants\n",
            "Agentic AI\n",
            "Agentic AI vs generative AI\n",
            "Caret right\n",
            "AI agent development\n",
            "What is AI agent development?\n",
            "AgentOps\n",
            "Caret right\n",
            "Types of AI agents\n",
            "Overview\n",
            "Simple reflex agent\n",
            "Caret right\n",
            "Components\n",
            "Overview\n",
            "Caret right\n",
            "Agentic workflows\n",
            "What are agentic workflows?\n",
            "Tutorial: Agentic workflows\n",
            "Communication\n",
            "Learning\n",
            "Memory\n",
            "Perception\n",
            "Planning\n",
            "Reasoning\n",
            "Caret right\n",
            "Tool calling\n",
            "What is tool calling?\n",
            "Tutorial: Ollama tool calling\n",
            "Tutorial: LM Studio tool calling\n",
            "Caret right\n",
            "Architecture\n",
            "Overview\n",
            "Caret right\n",
            "AI agent orchestration\n",
            "What is agent orchestration?\n",
            "Tutorial: Agent orchestration\n",
            "Caret right\n",
            "Multi-agent systems\n",
            "What are multi-agent systems?\n",
            "Tutorial: crewAI multi-agent call analysis\n",
            "Multi-agent collaboration\n",
            "Caret right\n",
            "ReAct\n",
            "What is ReAct?\n",
            "Tutorial: LangGraph ReAct agent\n",
            "Caret right\n",
            "ReWOO\n",
            "What is ReWOO?\n",
            "Tutorial: ReWOO reasoning agent\n",
            "Caret right\n",
            "Protocols\n",
            "Overvie\n"
          ]
        }
      ],
      "source": [
        "print(r[0][:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWvaK0l5sbvV",
        "outputId": "49c9afd8-6b2b-46ca-b5aa-e238f906d024"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_UkrFt8qy3ZpV8XBWBWRlBwaa', 'function': {'arguments': '{\"query\":\"langgraph\"}', 'name': 'search_web'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 49, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--fd16048e-50dd-4c5b-9d73-65828c032025-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'langgraph'}, 'id': 'call_UkrFt8qy3ZpV8XBWBWRlBwaa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 49, 'output_tokens': 15, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web]\n",
        "chatgpt_with_tools = chatgpt.bind_tools(tools)\n",
        "prompt = \"What is langgraph?\"\n",
        "response = chatgpt_with_tools.invoke(prompt)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN2-oP6qsijW",
        "outputId": "f4651ee4-a9c2-4309-f744-ac88feec2fad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'search_web',\n",
              "  'args': {'query': 'langgraph'},\n",
              "  'id': 'call_UkrFt8qy3ZpV8XBWBWRlBwaa',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "response.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km_nQy6CueVv"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "                At the end of the loop, you output an Answer.\n",
        "                Use Thought to describe your thoughts about the question you have been asked.\n",
        "                Use Action to run one of the actions available to you - then return PAUSE.\n",
        "                Observation will be the result of running those actions.\n",
        "                For the user query below, first break it into multiple sub queries or sub steps if needed.\n",
        "                The follow the below workflow for each sub query or sub step\n",
        "                Analyze, validate the relevant results and then compile to generate the final answer\n",
        "\n",
        "                Use the following workflow format:\n",
        "                Question: the input task you must solve\n",
        "                Thought: you should always think about what to do\n",
        "                Action: the action to take:\n",
        "                          - should be either to break down the task into sub tasks first if needed\n",
        "                          - refer to your trained knowledge or call the tool [search_web]\n",
        "                            if you need to get additional information from the web\n",
        "                Action Input: the input to the action\n",
        "                Observation: the result of the action\n",
        "                ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                Thought: I now know the final answer\n",
        "                Final Answer: the final answer to the original input question\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "   [\n",
        "       (\"system\", SYS_PROMPT),\n",
        "       (\"human\", \"Query: {query}\"),\n",
        "       MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "   ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC_SGaBPvV8f"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "tools = [search_web]\n",
        "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1AZmYhnvmMV",
        "outputId": "4d6a3ec3-2ef0-4d06-d70d-38dce90d3e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `search_web` with `{'query': 'LangGraph details, creator, key features'}`\n",
            "\n",
            "\n",
            "\u001b[0mSearching web and extracting page info\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:11<00:00,  2.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3m['LangGraph\\nProducts\\nFrameworks\\nLangGraph\\nLangChain\\nPlatforms\\nLangSmith\\nLangGraph Platform\\nResources\\nGuides\\nBlog\\nCustomer Stories\\nLangChain Academy\\nCommunity\\nEvents\\nChangelog\\nDocs\\nPython\\nLangGraph\\nLangSmith\\nLangChain\\nJavaScript\\nLangGraph\\nLangSmith\\nLangChain\\nCompany\\nAbout\\nCareers\\nPricing\\nGet a demo\\nSign up\\nBalance agent control with agency\\nGain control with LangGraph to design agents\\nthat reliably handle complex tasks.\\nStart building\\nIntroduction to LangGraph\\nLearn the basics of LangGraph in this LangChain Academy Course. You\\'ll learn how to build agents that automate real-world tasks with LangGraph orchestration.\\nEnroll for free\\nBook enterprise training\\nTrusted by companies shaping the future of agents\\nSee LangGraph use cases in production\\nControllable cognitive architecture for any task\\nLangGraph\\'s flexible framework supports diverse control flows – single agent, multi-agent, hierarchical, sequential – and robustly handles realistic, complex scenarios.\\nEnsure reliability with easy-to-add moderation and quality loops that prevent agents from veering off course.\\nUse LangGraph Platform to templatize your cognitive architecture so that tools, prompts, and models are easily configurable with LangGraph Platform Assistants.\\nSee the docs\\nThousands of companies build AI apps better with LangChain products.\\nRead our select customer stories.\\nDesigned for human-agent collaboration\\nWith built-in statefulness, LangGraph agents seamlessly collaborate with humans by writing drafts for review and awaiting approval before acting. Easily inspect the agent’s actions and \"time-travel\" to roll back and take a different action to correct course.\\nRead a conceptual guide\\nHow does LangGraph help?\\nGuide, moderate, and control your agent with human-in-the-loop.\\nPrevent agents from veering off course with easy-to-add moderation and quality controls. Add human-in-the-loop checks to steer and approve agent actions.\\nLearn how to add human-in-the-loop\\nBuild expressive, customizable agent workflows.\\nLangGraph’s low-level primitives provide the flexibility needed to create fully customizable agents. Design diverse control flows — single, multi-agent, hierarchical — all using one framework.\\nSee different agent architectures\\nPersist context for long-term interactions.\\nLangGraph’s built-in memory stores conversation histories and maintains context over time, enabling rich, personalized interactions across sessions.\\nLearn about agent memory\\nFirst-class streaming for better UX design.\\nBridge user expectations and agent capabilities with native token-by-token streaming, showing agent reasoning and actions in real time.\\nSee how to use streaming\\nFirst class streaming support for better UX design\\nBridge user expectations and agent capabilities with native token-by-token streaming and streaming of intermediate steps, helpful for showing agent reasoning and actions back to the user as they happen. Use LangGraph Platform\\'s API to deliver dynamic and interactive user experiences.\\nLearn more\\nIntroduction to LangGraph\\nLearn the basics of LangGraph in this LangChain Academy Course. You\\'ll learn how to build agents that automate real-world tasks with LangGraph orchestration.\\nEnroll for free\\nDeploy agents at scale, monitor carefully, iterate boldly\\nDesign agent-driven user experiences with LangGraph Platform\\'s APIs. Quickly deploy and scale your application with infrastructure built for agents. Choose from multiple deployment options.\\nFault-tolerant scalability\\nHandle large workloads gracefully with horizontally-scaling servers, task queues, and built-in persistence. Enhance resilience with intelligent caching and automated retries.\\nDynamic APIs for designing agent experience\\nCraft personalized user experiences with APIs featuring long-term memory to recall information across conversation sessions. Track, update, and rewind your app\\'s state for easy human steering and interaction. Kick off long-running background jobs for research-style or multi-step work.\\nIntegrated developer experience\\nSimplify prototyping, debugging, and sharing of agents in our visual LangGraph Studio. Deploy your application with 1-click deploy with our SaaS offering or within your own VPC. Then, monitor app performance with LangSmith.\\nWithout LangGraph Platform\\nWrite your own API endpoints for human-in-the-loop, background jobs, and more. Manage state and checkpointing. \\u2028Handle horizontal scaling and engineer fault tolerance. Continual maintenance and on-call.\\nWith LangGraph Platform\\nFocus on the app logic, not the infrastructure. Full batteries included — APIs, scalability, streaming, built in.\\nDevelopers trust LangGraph to build reliable agents.\\nLangGraph helps teams of all sizes, across all industries, build reliable agents ready for production.\\nHear how industry leaders use LangGraph\\n“LangChain is streets ahead with what they\\'ve put forward with LangGraph. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.”\\nGarrett Spong\\nPrincipal SWE\\n“LangGraph has been instrumental for our AI development. Its robust framework for building stateful, multi-actor applications with LLMs has transformed how we evaluate and optimize the performance of our AI guest-facing solutions. LangGraph enables granular control over the agent\\'s thought process, which has empowered us to make data-driven and deliberate decisions to meet the diverse needs of our guests.”\\nAndres Torres\\nSr. Solutions Architect\\n“It\\'s easy to build the prototype of a coding agent, but deceptively hard to improve its reliability. Replit wants to give a coding agent to millions of users — reliability is our top priority, and will remain so for a long time. LangGraph is giving us the control and ergonomics we need to build and ship powerful coding agents.”\\n“As Ally advances its exploration of Generative AI,\\nMichele Catasta\\nPresident\\n“As Ally advances its exploration of Generative AI, our tech labs is excited by LangGraph, the new library from LangChain, which is central to our experiments with multi-actor agentic workflows. We are committed to deepening our partnership with LangChain.”\\n“As Ally advances its exploration of Generative AI,\\nSathish Muthukrishnan\\nChief Information, Data and Digital Officer\\n“LangChain is streets ahead with what they\\'ve put forward with LangGraph. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.”\\nGarrett Spong\\nPrincipal SWE\\n“LangGraph has been instrumental for our AI development. Its robust framework for building stateful, multi-actor applications with LLMs has transformed how we evaluate and optimize the performance of our AI guest-facing solutions. LangGraph enables granular control over the agent\\'s thought process, which has empowered us to make data-driven and deliberate decisions to meet the diverse needs of our guests.”\\nAndres Torres\\nSr. Solutions Architect\\n“It\\'s easy to build the prototype of a coding agent, but deceptively hard to improve its reliability. Replit wants to give a coding agent to millions of users — reliability is our top priority, and will remain so for a long time. LangGraph is giving us the control and ergonomics we need to build and ship powerful coding agents.”\\n“As Ally advances its exploration of Generative AI,\\nMichele Catasta\\nPresident\\n“As Ally advances its exploration of Generative AI, our tech labs is excited by LangGraph, the new library from LangChain, which is central to our experiments with multi-actor agentic workflows. We are committed to deepening our partnership with LangChain.”\\n“As Ally advances its exploration of Generative AI,\\nSathish Muthukrishnan\\nChief Information, Data and Digital Officer\\nLangGraph FAQs\\nHow is LangGraph different from other agent frameworks?\\nOther agentic frameworks can work for simple, generic tasks but fall short for complex tasks bespoke to a company’s needs. LangGraph provides a more expressive framework to handle companies’ unique tasks without restricting users to a single black-box cognitive architecture.\\nDoes LangGraph impact the performance of my app?\\nLangGraph will not add any overhead to your code and is specifically designed with streaming workflows in mind.\\nIs LangGraph open source? Is it free?\\nYes. LangGraph is an MIT-licensed open-source library and is free to use.\\nHow are LangGraph and LangGraph Platform different?\\nLangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\\nLangGraph (open source)\\nLangGraph Platform\\nFeatures\\nDescription\\nStateful orchestration framework for agentic applications\\nScalable infrastructure for deploying LangGraph applications\\nSDKs\\nPython and JavaScript\\nPython and JavaScript\\nHTTP\\xa0APIs\\nNone\\nYes - useful for retrieving & updating state or long-term memory, or creating a configurable assistant\\nStreaming\\nBasic\\nDedicated mode for token-by-token messages\\nCheckpointer\\nCommunity contributed\\nSupported out-of-the-box\\nPersistence Layer\\nSelf-managed\\nManaged Postgres with efficient storage\\nDeployment\\nSelf-managed\\n- Cloud\\n- Hybrid\\n- Full self-hosted\\nScalability\\nSelf-managed\\nAuto-scaling of task queues and servers\\nFault-tolerance\\nSelf-managed\\nAutomated retries\\nConcurrency Control\\nSimple threading\\nSupports double-texting\\nScheduling\\nNone\\nCron scheduling\\nMonitoring\\nOpt-in LangSmith integration for observability\\nIntegrated with LangSmith for observability\\nIDE integration\\nLangGraph Studio for Desktop\\nLangGraph Studio for Desktop & Cloud\\nWhat are my deployment options for LangGraph Platform?\\nWe currently have the following deployment options for LangGraph applications:\\n\\u200d\\nCloud SaaS:\\nFully managed and hosted as part of LangSmith (our unified observability\\xa0& evals platform).\\xa0Deploy quickly, with automatic updates and zero maintenance.\\n\\u200d\\nHybrid\\n(SaaS control plane, self-hosted data plane). No data leaves your VPC. Provisioning and scaling is managed as a service.\\n\\u200d\\nFully\\nSelf-Hosted:\\nDeploy LangGraph entirely on your own infrastructure.\\n\\u200d\\nIf you want to try out a basic version of our LangGraph server in your environment, you can also self-host on our Developer plan and get up to 100k nodes executed per month for free.\\xa0Great for running hobbyist projects, with fewer features are available than in paid plans.\\n\\u200d\\nIs LangGraph Platform open source?\\nNo. LangGraph Platform is proprietary software.\\n\\u200d\\nThere is a free, self-hosted version of LangGraph Platform with access to basic features. The Cloud SaaS deployment option is free while in beta, but will eventually be a paid service. We will always give ample notice before charging for a service and reward our early adopters with preferential pricing. The Bring Your Own Cloud (BYOC) and Self-Hosted Enterprise options are also paid services.\\nContact our sales team\\nto learn more.\\n\\u200d\\nFor more information, see our\\nLangGraph Platform pricing page\\n.\\nReady to start shipping \\u2028reliable agents faster?\\nGet started with tools from the LangChain product suite for every step of the agent development lifecycle.\\nContact Us\\nSign Up\\nProducts\\nLangChain\\nLangSmith\\nLangGraph\\nResources\\nGuides\\nBlog\\nCustomer Stories\\nLangChain Academy\\nCommunity\\nEvents\\nChangelog\\nExperts\\nPython Docs\\nLangGraph\\nLangSmith\\nLangChain\\nJS Docs\\nLangGraph\\nLangSmith\\nLangChain\\nCompany\\nAbout\\nCareers\\nX\\nLinkedIn\\nYouTube\\nMarketing Assets\\nSecurity\\nSign up for our newsletter to stay up to date\\nThank you! Your submission has been received!\\nOops! Something went wrong while submitting the form.\\nAll systems\\noperational\\nPrivacy Policy\\nTerms of Service', 'LangGraph Tutorial to Build a Basic and Smart Chatbot\\nFor a hands-on learning experience to develop Agentic AI applications, join our Agentic AI Bootcamp today.\\nEarly Bird Discount\\nRegister\\nBootcamps\\nWe offer online and in-person learning programs in analytics, data science and AI. Designed for all levels, our hands-on programs offer flexibility and immersion.\\nView Testimonials\\nLarge Language Models Bootcamp\\nLarge Language Models Bootcamp\\nData Science Bootcamp\\nData Science Bootcamp\\nIntroduction to Power BI\\nIntroduction to Power BI\\nAgentic AI Bootcamp\\nAgentic AI Bootcamp\\nPython for Data Science\\nPython for Data Science\\nData Science for Business\\nData Science for Business\\nFind your ideal bootcamp! Set up a call with us today.\\nBook Now\\nCourses\\nLLM - Online Courses\\nJoin our dynamic live online Large Language Model (LLM) Courses, crafted for all proficiency levels. Enjoy flexibility and hands-on learning as we simplify complex concepts for your clear understanding.\\nFree Courses\\nLLM for Everyone\\nLLM for Everyone\\nIntroduction to Fine-Tuning LLM\\nIntroduction to Fine-Tuning LLM\\nRetrieval Augmented Generation\\nRetrieval Augmented Generation\\nMastering LangChain\\nMastering LangChain\\nPrompt Engineering for Everyone\\nPrompt Engineering for Everyone\\nEmbeddings and Transformer Architecture\\nEmbeddings and Transformer Architecture\\nFind your ideal courses! Set up a call with us today.\\nBook Now\\nReviews\\nReviews\\nEnabling learners to extract actionable insights from data while encouraging the use of AI. We aim to make data science accessible to everyone.\\nContact Us\\nSuccess Stories\\nSuccess Stories\\nAlumni\\nAlumni\\nCompanies\\nCompanies\\nTestimonials\\nTestimonials\\nConsulting\\nConsulting\\nTransform your business by harnessing the voice of your customers and employees. Tap into a wealth of internal and external data resources to revolutionize your sales, marketing, and support strategies.\\nCase Studies\\nData and Analytics\\nData and Analytics\\nLarge Language Models\\nLarge Language Models\\nWe will work with you to understand your needs.\\nBook Now\\nCommunity\\nCommunity\\nBecome a part of a platform for knowledge exchange, mutual growth, and learning. Learn from the wisdom of AI and Data experts.\\nPartner with us\\nEvents\\nEvents\\nNewsletter\\nNewsletter\\nDiscussion Forum\\nDiscussion Forum\\nPodcasts\\nPodcasts\\nFODAI\\nFODAI\\nTutorials\\nTutorials\\nShare your expertise and insights with our audience!\\nBecome a Speaker\\nBlog\\n/\\nBlog\\n/\\nLangGraph Tutorial to Revolutionize AI Agent Workflows\\nLangGraph Tutorial to Revolutionize AI Agent Workflows\\nPublished\\nAugust 23, 2024\\nLLM\\nHaider Ali\\nWant to Build AI agents that can reason, plan, and execute autonomously?\\nLearn More\\nIn the rapidly evolving world of artificial intelligence and\\nlarge language models\\n(LLMs), developers are constantly seeking ways to create more flexible, powerful, and intuitive AI agents.\\nWhile\\nLangChain\\nhas been a game-changer in this space, allowing for the creation of complex chains and agents, there’s been a growing need for even more sophisticated control over agent runtimes.\\nEnter LangGraph, a cutting-edge module built on top of LangChain that’s set to revolutionize how we design and implement AI workflows.\\nIn this blog, we present a detailed LangGraph tutorial on building a chatbot and revolutionizing AI agent workflows.\\nUnderstanding LangGraph\\nLangGraph is an extension of the\\nLangChain\\necosystem that introduces a novel approach to creating\\nAI agent\\nruntimes. At its core, LangGraph allows developers to represent complex workflows as cyclical graphs, providing a more intuitive and flexible way to design agent behaviors.\\nThe primary motivation behind LangGraph is to address the limitations of traditional directed acyclic graphs (DAGs) in representing AI workflows. While DAGs are excellent for linear processes, they fall short when it comes to implementing the kind of iterative, decision-based flows that advanced AI agents often require.\\nExplore the\\ndifference between LangChain and LlamaIndex\\nLangGraph solves this by enabling the creation of workflows with cycles, where an AI can revisit previous steps, make decisions, and adapt its behavior based on intermediate results. This is particularly useful in scenarios where an agent might need to refine its approach or gather additional information before proceeding.\\nKey Components of LangGraph\\nTo effectively use LangGraph, it’s crucial to understand its fundamental components:\\nNodes\\nNodes in LangGraph represent individual functions or tools that your AI agent can use. These can be anything from API calls to complex reasoning tasks performed by language models. Each node is a discrete step in your workflow that processes input and produces output.\\nEdges\\nEdges connect the nodes in your graph, defining the flow of information and control. LangGraph supports two types of edges:\\nSimple Edges\\n: These are straightforward connections between nodes, indicating that the output of one node should be passed as input to the next.\\nConditional Edges\\n: These are more complex connections that allow for dynamic routing based on the output of a node. This is where LangGraph truly shines, enabling adaptive workflows.\\nRead about\\nLangChain agents and their use for time series analysis\\nState\\nState is the information that can be passed between nodes in a whole graph. If you want to keep track of specific information during the workflow then you can use state.\\nThere are 2 types of graphs which you can make in LangGraph:\\nBasic Graph:\\nThe basic graph will only pass the output of the first node to the next node because it can’t contain states.\\nStateful Graph:\\nThis graph can contain a state which will be passed between nodes and you can access this state at any node.\\nLangGraph Tutorial Using a\\xa0 Simple Example: Build a Basic Chatbot\\nWe’ll create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\\nStart by creating a\\u202fStateGraph. A\\u202fStateGraph\\u202fobject defines the structure of our chatbot as a\\nstate machine\\n. We’ll add\\u202fnodes\\u202fto represent the LLM and functions our chatbot can call and\\u202fedges\\u202fto specify how the bot should transition between these functions.\\nExplore this\\nguide to building LLM chatbots\\nSo now our graph knows two things:\\nEvery\\u202fnode\\u202fwe define will receive the current\\u202fState\\u202fas input and return a value that updates that state.\\nmessages\\u202fwill be\\nappended\\nto the current list, rather than directly overwritten. This is communicated via the prebuilt\\nadd_messages\\nfunction in the\\u202fAnnotated\\u202fsyntax.\\nNext, add a\\nchatbot\\nnode. Nodes represent units of work. They are typically regular Python functions.\\nNotice\\nhow the\\u202fchatbot\\u202fnode function takes the current\\u202fState\\u202fas input and returns a dictionary containing an updated\\u202fmessages\\u202flist under the key “messages”. This is the basic pattern for all LangGraph node functions.\\nThe\\u202fadd_messages\\u202ffunction in our\\u202fState\\u202fwill append the LLM’s response messages to whatever messages are already in the state.\\nNext, add an\\u202fentry\\u202fpoint. This tells our graph\\nwhere to start its work\\neach time we run it.\\nSimilarly, set a\\u202ffinish\\u202fpoint. This instructs the graph\\n“Any time this node is run, you can exit.”\\nFinally, we’ll want to be able to run our graph. To do so, call “\\ncompile(\\n)” on the graph builder. This creates a “\\nCompiledGraph\\n” we can use invoke on our state.\\nYou can visualize the graph using the\\nget_graph\\nmethod and one of the “draw” methods, like\\ndraw_ascii\\nor\\ndraw_png\\n. The\\u202fdraw\\u202fmethods each require additional dependencies.\\nNow let’s run the chatbot!\\nTip:\\nYou can exit the chat loop at any time by typing “quit”, “exit”, or “q”.\\nAdvanced LangGraph Techniques\\nLangGraph’s true potential is realized when dealing with more complex scenarios. Here are some advanced techniques:\\nMulti-step reasoning: Create graphs where the AI can make multiple decisions, backtrack, or explore different paths based on intermediate results.\\nTool integration: Seamlessly incorporate various external tools and APIs into your workflow, allowing the AI to gather and process diverse information.\\nHuman-in-the-loop workflows: Design graphs that can pause execution and wait for human input at critical decision points.\\nDynamic graph modification: Alter the structure of the graph at runtime based on the AI’s decisions or external factors.\\nYou can also deepen your knowledge with our webinar on building multi-agent AI applications with LangGraph.\\nLearn\\nhow to build custom Q&A chatbots\\nReal-World Applications\\nLangGraph’s flexibility makes it suitable for a wide range of applications:\\nCustomer Service Bots:\\nCreate intelligent chatbots that can handle complex queries, access multiple knowledge bases, and escalate to human operators when necessary.\\nResearch Assistants:\\nDevelop AI agents that can perform literature reviews, synthesize information from multiple sources, and generate comprehensive reports.\\nAutomated Troubleshooting:\\nBuild expert systems that can diagnose and solve technical problems by following complex decision trees and accessing various diagnostic tools.\\nContent Creation Pipelines:\\nDesign workflows for AI-assisted content creation, including research, writing, editing, and publishing steps.\\nExplore the list of\\ntop AI content generators\\nConclusion\\nLangGraph represents a significant leap forward in the design and implementation of AI agent workflows. Enabling cyclical, state-aware graphs, opens up new possibilities for creating more intelligent, adaptive, and powerful AI systems.\\nAs the field of AI continues to evolve, tools like LangGraph will play a crucial role in shaping the next generation of AI applications.\\nWhether you’re building simple chatbots or complex AI-powered systems, LangGraph provides the flexibility and power to bring your ideas to life. As we continue to explore the potential of this tool, we can expect to see even more innovative and sophisticated AI applications emerging in the near future.\\nAre you curious to learn more about the role of LangGraph in the LLM ecosystem?\\xa0To boost your knowledge further, join our\\nLLM Bootcamp\\ntoday!\\nSubscribe to our newsletter\\nMonthly curated AI content, Data Science Dojo updates, and more.\\nSign up to get the latest on events and webinars\\nSign up\\nView Events\\nTraining Programs\\nLarge Language Models Bootcamp\\nData Science Bootcamp\\nPython for Data Science\\nIntroduction to Power BI\\nData Science for Business Leaders\\nPracticum Program\\nData Science Certificates\\nFellowships\\nSchedule\\nEnterprise\\nCorporate Training\\nAlumni Companies\\nData Science Consulting\\nHiring Partnerships\\nJob Board\\nCommunity\\nBlog\\nFuture of Data & AI\\nTutorials\\nDiscussions\\nGitLab\\nEvents\\nMachine Learning Demos\\nSuccess Stories\\nPodcast\\nAbout\\nCompany Info\\nTeam\\nPress\\nPicture Gallery\\nCareers\\nHiring\\nContact Us\\nNewsletter\\n+1 (877) 360-3442\\nFacebook-f\\nLinkedin\\nX-twitter\\nInstagram\\nYoutube\\nVimeo\\n© Copyright – Data Science Dojo |\\nPrivacy Policy\\n|\\nTerms of Service\\nDiscover more from Data Science Dojo\\nSubscribe to get the latest updates on AI, Data Science, LLMs, and Machine Learning.\\nContinue reading', \"AI Agents in LangGraph - DeepLearning.AI\\n✨ New course! Enroll in\\nBuilding and Evaluating Data Agents\\nExplore Courses\\nAI Newsletter\\nThe Batch\\nAndrew's Letter\\nData Points\\nML Research\\nBlog\\n✨ AI Dev x NYC\\nCommunity\\nForum\\nEvents\\nAmbassadors\\nAmbassador Spotlight\\nResources\\nCompany\\nAbout\\nCareers\\nContact\\nStart Learning\\nOverview\\nCourse Outline\\nInstructors\\nAll Courses\\nShort Courses\\nAI Agents in LangGraph\\nShort Course\\nIntermediate\\n1 Hour  32 Minutes\\nAI Agents in LangGraph\\nInstructors\\n:\\nHarrison Chase, Rotem Weiss\\nEnroll for Free\\nAll Courses\\nShort Courses\\nAI Agents in LangGraph\\nIntermediate\\n1 Hour  32 Minutes\\n9 Video Lessons\\n6 Code Examples\\nInstructors: Harrison Chase, Rotem Weiss\\nLangChain, Tavily\\nWhat you'll learn\\nLearn about LangGraph’s components and how they enable the development, debugging, and maintenance of AI agents.\\nIntegrate agentic search capabilities to enhance agent knowledge and performance.\\nLearn directly from\\nLangChain founder Harrison Chase and Tavily founder Rotem Weiss.\\nAbout this course\\nLangChain, a popular open source framework for building LLM applications, recently introduced LangGraph. This extension allows developers to create highly controllable agents.\\nIn this course you will learn to build an agent from scratch using Python and an LLM, and then you will rebuild it using LangGraph, learning about\\xa0 its components and how to combine them to build flow-based applications.\\nAdditionally, you will learn about agentic search, which returns multiple answers in an agent-friendly format, enhancing the agent’s built-in knowledge. This course will show you how to use agentic search in your applications to provide better data for agents to enhance their output.\\nIn detail:\\nBuild an agent from scratch, and understand the division of tasks between the LLM and the code around the LLM.\\nImplement the agent you built using LangGraph.\\nLearn how agentic search retrieves multiple answers in a predictable format, unlike traditional search engines that return links.\\nImplement persistence in agents, enabling state management across multiple threads, conversation switching, and the ability to reload previous states.\\nIncorporate human-in-the-loop into agent systems.\\nDevelop an agent for essay writing, replicating the workflow of a researcher working on this task.\\nStart building more controllable agents using LangGraph!\\nWho should join?\\nIf you have intermediate Python knowledge and want to learn how to create more controllable agents using the LangGraph open source framework, this course is for you.\\nCourse Outline\\n9\\nLessons・\\n6\\nCode Examples\\nIntroduction\\nVideo\\n・\\n6 mins\\nBuild an Agent from Scratch\\nVideo with code examples\\n・\\n12 mins\\nLangGraph Components\\nVideo with code examples\\n・\\n19 mins\\nAgentic Search Tools\\nVideo with code examples\\n・\\n5 mins\\nPersistence and Streaming\\nVideo with code examples\\n・\\n9 mins\\nHuman in the loop\\nVideo with code examples\\n・\\n14 mins\\nEssay Writer\\nVideo with code examples\\n・\\n18 mins\\nLangChain Resources\\nVideo\\n・\\n2 mins\\nConclusion\\nVideo\\n・\\n4 mins\\nQuiz\\nReading\\n・\\n1 min\\nInstructors\\nHarrison Chase\\nCo-Founder and CEO of\\nLangChain\\nRotem Weiss\\nCo-founder and CEO of\\nTavily\\nAI Agents in LangGraph\\nIntermediate\\n1 Hour  32 Minutes\\n9 Video Lessons\\n6 Code Examples\\nInstructors: Harrison Chase, Rotem Weiss\\nLangChain, Tavily\\nEnroll for Free\\nRelated Courses\\nMulti AI Agent Systems with crewAI\\nAI Agentic Design Patterns with AutoGen\\nLLMs as Operating Systems: Agent Memory\\nCourse access is free for a limited time during the DeepLearning.AI learning platform beta!\\nEnroll for Free\\nWant to learn more about Generative AI?\\nKeep learning with updates on curated AI news, courses, and events, as well as Andrew’s thoughts from DeepLearning.AI!\\nEnroll for Free\\nCourses\\nThe Batch\\nCommunity\\nCareers\\nAbout\", 'Build a Tool-Calling AI Agent with LangChain, LangGraph and OpenAI Models\\nHome\\nSubjects\\nTutors\\nPremium\\nExam Study Guides\\nBooks\\nAbout\\nAwards\\nMerchandise\\nPartners\\nSupport\\nContact\\nSign In\\nJoin Academy\\nAcademy Membership\\nBuild a Tool-Calling AI Agent with LangChain, LangGraph and OpenAI Models\\nAgentic AI\\nLangChain\\nOpenAI\\nPython\\nArtificial Intelligence\\nby\\nAI Developer\\nSeptember 26, 2025 ∙\\n3 min read\\nWritten by\\nAI Developer\\nAs an AI Developer, I design and implement AI systems.\\nYour AI Journey\\nSpeed up your Streamlit App with Caching\\nEmbedding Models vs. Chat Models: Understanding the Difference\\nHow to deploy a Docusaurus Website to GitHub Pages\\n📘\\nIntroduction\\nWelcome to this hands-on\\nLangChain + LangGraph tutorial\\n! In this guide, we’ll build an\\nAI agent with tool-calling capabilities\\nusing\\nLangChain, LangGraph, and OpenAI models\\n.\\nInstead of just answering questions, our agent will be able to\\ninvoke a Python function\\nwhen needed. We’ll demonstrate this with a simple tool that greets users — the perfect starting point to understand how tool integration works.\\n💡\\nWhat are LangChain and LangGraph?\\nLangChain\\nis a Python framework for building applications powered by LLMs. It gives you tools to define prompts, memory, tools, and workflows — making it possible to build more than just chatbots.\\nLangGraph\\nextends LangChain by allowing\\ngraph-based workflows\\n. You can define\\nnodes\\n(steps) and\\nedges\\n(transitions) to control how agents reason, plan, and act.\\nTogether with\\nOpenAI models\\n, this stack allows you to:\\n🤖 Build context-aware agents\\n🛠️ Equip them with tools (e.g., APIs, calculators, or custom Python functions)\\n🔗 Control workflows with graph structures\\n⚡ Scale from simple prototypes to powerful assistants\\n💡\\nIn this tutorial, we’ll focus on\\ntool calling\\n— a core capability of modern AI agents.\\n✅ Prerequisites\\nBefore starting, make sure you have the following:\\n🐍☑️\\nPython\\ninstalled\\n📦☑️\\nPip\\ninstalled\\n🌐☑️ A\\nvirtual environment (venv)\\ncreated and activated\\n🔑☑️ An\\nOpenAI API key\\ngenerated (get one from\\nOpenAI\\n)\\n🔐☑️ OpenAI API key set as\\nenvironment variable\\nOPENAI_API_KEY\\n📦1️⃣ Install Libraries\\nInstall the following Python packages using\\npip\\n:\\npip install langchain-openai langgraph\\n📥2️⃣ Import Libraries\\nStart by importing the required Python modules:\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.prebuilt import create_react_agent\\nfrom langchain_core.tools import tool\\n🛠️3️⃣ Define a Tool\\nWe’ll create a simple\\nPython greeting function\\nand register it as a tool so that the agent can call it when needed.\\n@tool\\ndef greet_user(name: str) -> str:\\n    \"\"\"Greet the user with a personalized welcome message.\\n\\n    Args:\\n        name: The name of the user.\\n    \"\"\"\\n    return f\"Hello, {name}! Welcome to the Deep Learning Nerds Academy\"\\nYou can view this post with the tier:\\n      Academy Membership\\nJoin academy now to read the post and get access to the full library of premium posts for academy members only.\\nJoin Academy\\nAlready have an account?\\nSign In\\nNewer post\\nEmbedding Models vs. Chat Models: Understanding the Difference\\nOlder post\\nHow to deploy a Docusaurus Website to GitHub Pages\\nYou might also like\\nEmbedding Models vs. Chat Models: Understanding the Difference\\nby\\nData Scientist\\nBuild an AI Agent with LangChain, LangGraph and OpenAI Models\\nby\\nAI Developer\\nHow to Get JSON Structured Output from AI Agents with the OpenAI Agents SDK\\nby\\nAI Developer\\nHow to Get JSON Structured Output from LLMs with the OpenAI Python SDK\\nby\\nAI Developer\\nHow to add MCP Servers to your AI Agent using OpenAI Agents SDK\\nby\\nAI Developer\\nAcademy Membership\\nGet access to all posts.\\nJoin Academy →\\nThe Deep Learning Nerds Academy is a learning platform for Artificial Intelligence, Data Science, Data Analytics and Data Engineering containing hands-on tutorials, best practices and career advices.\\nJoin Academy →\\nGet access to all posts.\\nSocial\\nFacebook\\nX/Twitter\\nGitHub\\nInstagram\\nKo-fi\\nLinkedIn\\nCompany\\nHome\\nAbout\\nMerchandise\\nSupport\\nContact\\nAcademy\\nSign In\\nMembership\\nSubjects\\nTutors\\nPremium\\nLegal\\nImpressum / Site Notice\\nDatenschutz / Privacy Policy\\n©\\nDeep Learning Nerds\\n2025.\\nYou’ve successfully subscribed to Deep Learning Nerds | The ultimate Learning Platform for AI and Data Science\\nWelcome back! You’ve successfully signed in.\\nGreat! You’ve successfully signed up.\\nSuccess! Your email is updated.\\nYour link has expired\\nSuccess! Check your email for magic link to sign-in.', 'Attention Required! | Cloudflare\\nPlease enable cookies.\\nSorry, you have been blocked\\nYou are unable to access\\nreadmedium.com\\nWhy have I been blocked?\\nThis website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.\\nWhat can I do to resolve this?\\nYou can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.\\nCloudflare Ray ID:\\n9879cad61a079854\\n•\\nYour IP:\\nClick to reveal\\n34.23.49.122\\n•\\nPerformance & security by\\nCloudflare']\u001b[0m\u001b[32;1m\u001b[1;3mLangGraph is a sophisticated framework designed to enhance the development and deployment of AI agents. It is an extension of the LangChain ecosystem, which is a popular open-source framework for building applications powered by large language models (LLMs). LangGraph introduces a novel approach to creating AI agent runtimes by allowing developers to represent complex workflows as cyclical graphs, providing a more intuitive and flexible way to design agent behaviors.\n",
            "\n",
            "### Key Features of LangGraph:\n",
            "1. **Controllable Cognitive Architecture**: LangGraph supports diverse control flows such as single agent, multi-agent, hierarchical, and sequential, allowing for robust handling of complex scenarios.\n",
            "\n",
            "2. **Human-Agent Collaboration**: It is designed for seamless collaboration between agents and humans, with built-in statefulness that allows agents to write drafts for review and await approval before acting.\n",
            "\n",
            "3. **Expressive, Customizable Workflows**: LangGraph provides low-level primitives for creating fully customizable agents, supporting diverse control flows using a single framework.\n",
            "\n",
            "4. **Persistence and Memory**: It includes built-in memory to store conversation histories and maintain context over time, enabling rich, personalized interactions across sessions.\n",
            "\n",
            "5. **Streaming Support**: LangGraph offers first-class streaming support for better UX design, allowing for real-time display of agent reasoning and actions.\n",
            "\n",
            "6. **Scalability and Fault Tolerance**: The platform supports fault-tolerant scalability with horizontally-scaling servers, task queues, and built-in persistence, enhancing resilience with intelligent caching and automated retries.\n",
            "\n",
            "7. **Integrated Developer Experience**: LangGraph Studio simplifies prototyping, debugging, and sharing of agents, with options for 1-click deployment and performance monitoring.\n",
            "\n",
            "### Creator:\n",
            "LangGraph is developed by LangChain, a company known for its contributions to the AI and LLM space. The framework is part of their suite of tools designed to build and scale AI workloads effectively.\n",
            "\n",
            "LangGraph is particularly useful for creating AI agents that can reason, plan, and execute autonomously, making it suitable for applications like customer service bots, research assistants, automated troubleshooting, and content creation pipelines. It is open-source and available under the MIT license, allowing developers to freely use and modify it for their needs.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Tell me about LangGraph in detail including who made it and key features.\n",
        "            Do not guess answers, only answer if you are sure\"\"\"\n",
        "response = agent_executor.invoke({\"query\": prompt})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "8DDP9qSLvsK6",
        "outputId": "53634fb0-be3f-4c89-e659-cbc8808c1abd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangGraph is a sophisticated framework designed to enhance the development and deployment of AI agents. It is an extension of the LangChain ecosystem, which is a popular open-source framework for building applications powered by large language models (LLMs). LangGraph introduces a novel approach to creating AI agent runtimes by allowing developers to represent complex workflows as cyclical graphs, providing a more intuitive and flexible way to design agent behaviors.\n\n### Key Features of LangGraph:\n1. **Controllable Cognitive Architecture**: LangGraph supports diverse control flows such as single agent, multi-agent, hierarchical, and sequential, allowing for robust handling of complex scenarios.\n\n2. **Human-Agent Collaboration**: It is designed for seamless collaboration between agents and humans, with built-in statefulness that allows agents to write drafts for review and await approval before acting.\n\n3. **Expressive, Customizable Workflows**: LangGraph provides low-level primitives for creating fully customizable agents, supporting diverse control flows using a single framework.\n\n4. **Persistence and Memory**: It includes built-in memory to store conversation histories and maintain context over time, enabling rich, personalized interactions across sessions.\n\n5. **Streaming Support**: LangGraph offers first-class streaming support for better UX design, allowing for real-time display of agent reasoning and actions.\n\n6. **Scalability and Fault Tolerance**: The platform supports fault-tolerant scalability with horizontally-scaling servers, task queues, and built-in persistence, enhancing resilience with intelligent caching and automated retries.\n\n7. **Integrated Developer Experience**: LangGraph Studio simplifies prototyping, debugging, and sharing of agents, with options for 1-click deployment and performance monitoring.\n\n### Creator:\nLangGraph is developed by LangChain, a company known for its contributions to the AI and LLM space. The framework is part of their suite of tools designed to build and scale AI workloads effectively.\n\nLangGraph is particularly useful for creating AI agents that can reason, plan, and execute autonomously, making it suitable for applications like customer service bots, research assistants, automated troubleshooting, and content creation pipelines. It is open-source and available under the MIT license, allowing developers to freely use and modify it for their needs."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HSkQe92zXlOG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}